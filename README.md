# ğŸ¤– Chat-Analyst â€“ Your Local QA Analyst for Customer Support

Chat-Analyst is a lightweight, privacy-conscious, AI-powered tool that evaluates customer-agent chat transcripts for soft skills like tone, empathy, and communication quality. Powered by open-source LLMs via Together.ai, it helps automate QA reviewsâ€”without ever storing your data.

![App Screenshot](img/app1.png)

---

## ğŸ” What It Does

- âœ… Parses raw customer support chats (copy-paste or file upload)
- âœ… Preprocesses and formats the conversation
- âœ… Uses an LLM to provide structured QA feedback
- âœ… Displays raw, processed, and final evaluation reports
- âœ… Works locally with minimal setupâ€”privacy first!

---

## ğŸš€ Features

- ğŸ§  AI-Powered QA Evaluation: Uses Meta Llama Vision via Together.ai for detailed analysis.
- ğŸ“ Soft-Skill Assessment: Evaluates tone, professionalism, clarity, and flow.
- ğŸ“‚ Paste or Upload: Accepts direct input or .txt files.
- ğŸ“Š Visual Output: Multiple tabs for chat, parsed data, and report card.
- ğŸ”’ Privacy-First: No data is stored or logged.

---

## ğŸ–¼ Interface Screenshots

| Chat Upload & Preprocessing | Chat Analysis | Report Card View |
|-----------------------------|---------------------|--------------|
| ![](img/app3.png) | ![](img/app1.png) | ![](img/app2.png) |

---

## ğŸ›  Installation

1. **Clone the repo:**
   ```bash
   git clone https://github.com/yourusername/chat-analyst.git
   cd chat-analyst

2. **Create and activate a virtual environment (optional but recommended):**
    ```bash
    python -m venv venv
    source venv/bin/activate  # or venv\Scripts\activate on Windows

3. **Install dependencies:**
    ```bash
    pip install -r requirements.txt

4. **Add your API key:**
    ```bash
    TOGETHER_API_KEY=your_together_api_key_here

## â–¶ï¸ Running the App
    streamlit run app.py

## ğŸ“‚ Project Structure
    
    chat-analyst/
    â”‚
    â”œâ”€â”€ app.py                 # Main Streamlit frontend
    â”œâ”€â”€ src/                   # Chat parsing and preprocessing
    â”œâ”€â”€ llm_engine/            # Feedback engine + LLM wrappers
    â”œâ”€â”€ prompts/               # Prompt templates
    â”œâ”€â”€ schemas/               # JSON structure for feedback
    â”œâ”€â”€ img/                   # UI screenshots
    â”œâ”€â”€ .env.template          # Template file for API key
    â”œâ”€â”€ requirements.txt       # Python dependencies
    â””â”€â”€ README.md              # This file

## ğŸ“Œ Notes

- ğŸ’¡ If the model output is invalid or malformed, fallback handling will trigger.
- ğŸ›¡ This app never stores your chatsâ€”only processes in-memory.
- â± Performance tested on chats up to ~5K tokens.

## ğŸ“ƒ License
MIT License. Feel free to fork, use, or contribute!

## ğŸ™‹â€â™‚ï¸ Author
Built by Kuldeep Gupta.
ğŸ“§ Contact: kuldeep.gupta2603@gmail.com